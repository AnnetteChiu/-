{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.16","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"papermill":{"default_parameters":{},"duration":61.13523,"end_time":"2025-04-20T14:27:43.483904","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-04-20T14:26:42.348674","version":"2.6.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/annettelianchiu/personalized-nike-recommender?scriptVersionId=241217178\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# **Personalized Carbonated Drink Recommender**\n\n# Key Features Implemented:\n\n**Embeddings**: Used Gemini's embedding-001 model to create vector representations of drink descriptions and user queries for semantic understanding.\n\n**Retrieval Augmented Generation (RAG)**: Implemented a basic RAG system. User queries are embedded, and the most semantically similar drinks from a pre-defined dataset are retrieved. This retrieved context is then passed to the generative model.\n\n**Function Calling**: Defined Python functions (e.g., to filter drinks by specific nutritional criteria) and provided their schemas to the Gemini model. The model can decide to call these functions to fulfill parts of the user request.\n\n**Structured Output / JSON Mode**: Configured the Gemini Pro model to output its recommendations in a specific JSON format, making the results easy to parse and use programmatically.\n\n**Long Context Window (Implicit)**: While not explicitly demonstrated with a single massive prompt, the RAG process benefits from Gemini's long context capability by allowing the model to process the user's query plus the retrieved context from multiple relevant drinks simultaneously.\n\n**Dietary & Health Considerations**: Incorporated through the data structure (calories, sugar, caffeine, ingredients), RAG retrieval based on descriptive terms (e.g., \"low sugar\"), and specific function calls (e.g., filtering by max calories).","metadata":{"execution":{"iopub.execute_input":"2025-04-17T12:09:35.889478Z","iopub.status.busy":"2025-04-17T12:09:35.889124Z","iopub.status.idle":"2025-04-17T12:09:35.897034Z","shell.execute_reply":"2025-04-17T12:09:35.895949Z","shell.execute_reply.started":"2025-04-17T12:09:35.889456Z"},"papermill":{"duration":0.005483,"end_time":"2025-04-20T14:26:47.001119","exception":false,"start_time":"2025-04-20T14:26:46.995636","status":"completed"},"tags":[]}},{"cell_type":"code","source":"\"\"\"\nPersonalized Carbonated Drink Recommender using Gemini\n\nThis Notebook demonstrates how to build a personalized carbonated\ndrink recommender system using Google's Gemini models. It incorporates\nseveral advanced features:\n\n1. Embeddings: For semantic understanding of drinks and user queries.\n2. Retrieval Augmented Generation (RAG): To ground recommendations in factual\n   drink data.\n3. Function Calling: To allow the model to interact with specific data\n   filtering tools.\n4. Structured Output (JSON Mode): To get predictable, parseable results.\n5. Long Context Window (Implicit): Leveraged by RAG to process retrieved\n   information alongside the query.\n6. Dietary & Health Considerations: Factored into the data and recommendation\n   process.\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2025-05-22T09:45:19.860693Z","iopub.execute_input":"2025-05-22T09:45:19.860888Z","iopub.status.idle":"2025-05-22T09:45:19.870905Z","shell.execute_reply.started":"2025-05-22T09:45:19.86087Z","shell.execute_reply":"2025-05-22T09:45:19.869981Z"},"papermill":{"duration":0.016883,"end_time":"2025-04-20T14:26:47.023298","exception":false,"start_time":"2025-04-20T14:26:47.006415","status":"completed"},"tags":[],"trusted":true},"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"\"\\nPersonalized Carbonated Drink Recommender using Gemini\\n\\nThis Notebook demonstrates how to build a personalized carbonated\\ndrink recommender system using Google's Gemini models. It incorporates\\nseveral advanced features:\\n\\n1. Embeddings: For semantic understanding of drinks and user queries.\\n2. Retrieval Augmented Generation (RAG): To ground recommendations in factual\\n   drink data.\\n3. Function Calling: To allow the model to interact with specific data\\n   filtering tools.\\n4. Structured Output (JSON Mode): To get predictable, parseable results.\\n5. Long Context Window (Implicit): Leveraged by RAG to process retrieved\\n   information alongside the query.\\n6. Dietary & Health Considerations: Factored into the data and recommendation\\n   process.\\n\""},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"# @title Setup\n# Install necessary libraries\n!pip uninstall -qqy jupyterlab # Remove unused conflicting packages\n!pip install -U -q \"google-generativeai==0.8.5\" \"numpy==1.26.4\" \"scikit-learn==1.5.2\" \"rich==13.7.1\" \"toolz==0.11.2\" pandas","metadata":{"papermill":{"duration":29.00822,"end_time":"2025-04-20T14:27:16.036414","exception":false,"start_time":"2025-04-20T14:26:47.028194","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T11:15:40.942466Z","iopub.execute_input":"2025-05-22T11:15:40.942652Z","iopub.status.idle":"2025-05-22T11:16:03.565488Z","shell.execute_reply.started":"2025-05-22T11:15:40.942631Z","shell.execute_reply":"2025-05-22T11:16:03.560871Z"}},"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# **Setup**: \n\nInstalls and imports necessary libraries (google-generativeai, pandas, numpy, scikit-learn). Configures the Gemini API key (obtained using AI Studio)","metadata":{"papermill":{"duration":0.005307,"end_time":"2025-04-20T14:27:16.047478","exception":false,"start_time":"2025-04-20T14:27:16.042171","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Import required libraries\nimport google.generativeai as genai   # Main library for Gemini API access\nimport json                           # For handling JSON data (structured output, function calling)                           \nimport pandas as pd                   # For data manipulation (our drink database)\nimport numpy as np                    # For numerical operations, especially with embeddings\nfrom sklearn.metrics.pairwise import cosine_similarity # For comparing embeddings\nimport textwrap                       # For formatting text output nicely","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":5.605227,"end_time":"2025-04-20T14:27:21.658503","exception":false,"start_time":"2025-04-20T14:27:16.053276","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T11:16:32.394121Z","iopub.execute_input":"2025-05-22T11:16:32.394464Z","iopub.status.idle":"2025-05-22T11:16:32.405379Z","shell.execute_reply.started":"2025-05-22T11:16:32.394437Z","shell.execute_reply":"2025-05-22T11:16:32.399732Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"GOOGLE_API_KEY\")\ngenai.configure(api_key=secret_value_0)","metadata":{"papermill":{"duration":0.210467,"end_time":"2025-04-20T14:27:21.874599","exception":false,"start_time":"2025-04-20T14:27:21.664132","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T11:20:04.580949Z","iopub.execute_input":"2025-05-22T11:20:04.581327Z","iopub.status.idle":"2025-05-22T11:20:04.686077Z","shell.execute_reply.started":"2025-05-22T11:20:04.581284Z","shell.execute_reply":"2025-05-22T11:20:04.6802Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Define the models to use\nEMBEDDING_MODEL_NAME = \"models/embedding-001\"     # Model for creating text embeddings\nGENERATIVE_MODEL_NAME = \"gemini-1.5-flash-latest\" # Powerful generative model with function calling & JSON mode support (gemini-1.5-pro-latest is also a good option)","metadata":{"execution":{"iopub.status.busy":"2025-05-22T11:20:11.934043Z","iopub.execute_input":"2025-05-22T11:20:11.93439Z","iopub.status.idle":"2025-05-22T11:20:11.944222Z","shell.execute_reply.started":"2025-05-22T11:20:11.934364Z","shell.execute_reply":"2025-05-22T11:20:11.939873Z"},"papermill":{"duration":0.011473,"end_time":"2025-04-20T14:27:21.891482","exception":false,"start_time":"2025-04-20T14:27:21.880009","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"# Data Preparation: \n\nCreates a sample pandas DataFrame (df_drinks) containing information about various carbonated drinks. Crucially, it includes nutritional details (calories, sugar, caffeine) and boolean flags for common dietary needs (sugar-free, caffeine-free, zero-calorie). A Combined_Text column is generated to provide rich input for the embedding model.\n","metadata":{"papermill":{"duration":0.004861,"end_time":"2025-04-20T14:27:21.901635","exception":false,"start_time":"2025-04-20T14:27:21.896774","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# @title 1. Data Preparation: Carbonated Drink Dataset\n\n# Create a sample dataset of carbonated drinks.\n# In a real application, this would come from a database or larger file.\n# We include nutritional info, descriptions, and flags for dietary needs.\ndata = {\n    'ID': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n    'Name': [\n        \"Nike Air Force\", \"Nike Air Force 1\", \"Nike Air Force\", \"Nike Air Force\",\n        \"Nike Air Max\", \"Sparkling Water (Natural)\", \"Sparkling Water (Lime)\",\n        \"Zero Sugar Energy Drink\", \"Craft Root Beer\", \"Grape Soda Pop\",\n        \"Caffeine-Free Cola\", \"Zero Calorie Sparkling Raspberry\"\n    ],\n    'Description': [\n        \"The original cola taste. Bold, refreshing, and timeless.\",\n        \"Same great cola taste, zero sugar. Perfect for calorie-conscious drinkers.\",\n        \"Crisp and clean lemon and lime flavors. Refreshing and bubbly.\",\n        \"A sunny burst of sweet orange flavor. Tangy and invigorating.\",\n        \"Real ginger flavor with a spicy kick. Soothing and effervescent.\",\n        \"Pure, crisp sparkling water. No added flavors or sweeteners.\",\n        \"Sparkling water infused with natural lime essence. Zero calories, zero sugar.\",\n        \"Provides a boost of energy without sugar. Contains caffeine and B vitamins.\",\n        \"Rich and creamy traditional root beer flavor. Made with cane sugar.\",\n        \"Sweet and bubbly grape flavor. A fun, nostalgic treat.\",\n        \"Classic cola flavor without the caffeine kick. Enjoy anytime.\",\n        \"Delicious raspberry flavored sparkling water with zero calories and zero sugar.\"\n    ],\n    'Flavor Profile': [\n        \"Cola, Sweet\", \"Cola, Aspartame\", \"Lemon, Lime, Citrus\", \"Orange, Citrus, Sweet\",\n        \"Ginger, Spicy\", \"Neutral, Bubbly\", \"Lime, Citrus, Tart\",\n        \"Mixed Fruit, Artificial Sweetener, Energy Boost\", \"Root Beer, Vanilla, Sweet\",\n        \"Grape, Sweet\", \"Cola, Sweet\", \"Raspberry, Fruity, Tart\"\n    ],\n    'Calories (per 12oz)': [140, 0, 100, 160, 120, 0, 0, 10, 180, 170, 140, 0],\n    'Sugar (g per 12oz)': [39, 0, 27, 44, 32, 0, 0, 0, 48, 45, 39, 0],\n    'Caffeine (mg per 12oz)': [34, 46, 0, 0, 0, 0, 0, 160, 0, 0, 0, 0],\n    'Ingredients': [\n        \"Carbonated Water, High Fructose Corn Syrup, Caramel Color, Phosphoric Acid, Natural Flavors, Caffeine\",\n        \"Carbonated Water, Caramel Color, Aspartame, Phosphoric Acid, Potassium Benzoate (Preservative), Natural Flavors, Citric Acid, Caffeine\",\n        \"Carbonated Water, High Fructose Corn Syrup, Citric Acid, Natural Flavors, Sodium Citrate, Sodium Benzoate (Preservative)\",\n        \"Carbonated Water, High Fructose Corn Syrup, Citric Acid, Sodium Benzoate (Preservative), Natural Flavors, Modified Food Starch, Ester Gum, Yellow 6, Brominated Vegetable Oil\",\n        \"Carbonated Water, High Fructose Corn Syrup, Citric Acid, Natural Flavors, Sodium Benzoate (Preservative), Caramel Color\",\n        \"Carbonated Water\",\n        \"Carbonated Water, Natural Lime Flavor\",\n        \"Carbonated Water, Citric Acid, Taurine, Sodium Citrate, Natural Flavors, Panax Ginseng Extract, L-Carnitine Tartrate, Caffeine, Sucralose, Sodium Benzoate (Preservative), Niacinamide (Vit B3), D-Calcium Pantothenate (Vit B5), Salt, Acesulfame Potassium, Pyridoxine Hydrochloride (Vit B6), Yellow 5, Cyanocobalamin (Vit B12)\",\n        \"Carbonated Water, Cane Sugar, Caramel Color, Natural and Artificial Flavors, Sodium Benzoate (Preservative), Citric Acid\",\n        \"Carbonated Water, High Fructose Corn Syrup, Sodium Benzoate (Preservative), Citric Acid, Natural and Artificial Flavors, Red 40, Blue 1\",\n        \"Carbonated Water, High Fructose Corn Syrup, Caramel Color, Phosphoric Acid, Natural Flavors, Potassium Benzoate (Preservative)\",\n        \"Carbonated Water, Citric Acid, Natural Raspberry Flavor, Potassium Benzoate (Preservative), Aspartame, Acesulfame Potassium\"\n    ],\n    'Is_Sugar_Free': [False, True, False, False, False, True, True, True, False, False, False, True],\n    'Is_Caffeine_Free': [False, False, True, True, True, True, True, False, True, True, True, True],\n    'Is_Zero_Calorie': [False, True, False, False, False, True, True, False, False, False, False, True] # Note: Diet Cola is 0 cal, Energy Drink is 10 cal\n}","metadata":{"papermill":{"duration":0.016409,"end_time":"2025-04-20T14:27:21.923136","exception":false,"start_time":"2025-04-20T14:27:21.906727","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T11:20:17.01958Z","iopub.execute_input":"2025-05-22T11:20:17.019946Z","iopub.status.idle":"2025-05-22T11:20:17.035516Z","shell.execute_reply.started":"2025-05-22T11:20:17.019917Z","shell.execute_reply":"2025-05-22T11:20:17.031047Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Create a pandas DataFrame\ndf_drinks = pd.DataFrame(data)\n\n# Combine relevant text fields for embedding\n# We create a more descriptive text entry for each drink to improve embedding quality.\ndf_drinks['Combined_Text'] = df_drinks.apply(\n    lambda row: f\"Name: {row['Name']}. Description: {row['Description']}. Flavor: {row['Flavor Profile']}. \"\n                f\"Calories: {row['Calories (per 12oz)']}. Sugar: {row['Sugar (g per 12oz)']}g. Caffeine: {row['Caffeine (mg per 12oz)']}mg. \"\n                f\"{'Sugar-free. ' if row['Is_Sugar_Free'] else ''}\"\n                f\"{'Caffeine-free. ' if row['Is_Caffeine_Free'] else ''}\"\n                f\"{'Zero-calorie.' if row['Is_Zero_Calorie'] else ''}\",\n    axis=1 # Apply function row-wise\n)\n\n# Display the first few rows of the DataFrame with the combined text\nprint(\"Sample Nike Data:\")\nprint(df_drinks[['Name', 'Combined_Text']].head())","metadata":{"papermill":{"duration":0.040369,"end_time":"2025-04-20T14:27:21.968879","exception":false,"start_time":"2025-04-20T14:27:21.92851","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T11:20:22.305683Z","iopub.execute_input":"2025-05-22T11:20:22.306053Z","iopub.status.idle":"2025-05-22T11:20:22.33135Z","shell.execute_reply.started":"2025-05-22T11:20:22.306024Z","shell.execute_reply":"2025-05-22T11:20:22.325502Z"}},"outputs":[{"name":"stdout","text":"Sample Nike Data:\n               Name                                      Combined_Text\n0    Nike Air Force  Name: Nike Air Force. Description: The origina...\n1  Nike Air Force 1  Name: Nike Air Force 1. Description: Same grea...\n2    Nike Air Force  Name: Nike Air Force. Description: Crisp and c...\n3    Nike Air Force  Name: Nike Air Force. Description: A sunny bur...\n4      Nike Air Max  Name: Nike Air Max. Description: Real ginger f...\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"# Embeddings:\n\nDefines get_embeddings to generate vector embeddings for a list of texts using the specified Gemini embedding model (models/embedding-001). It uses task_type=\"RETRIEVAL_DOCUMENT\" as these embeddings represent the documents we'll search against.Generates embeddings for all drinks based on their Combined_Text and stores them in drink_embeddings.\n\n","metadata":{"papermill":{"duration":0.005146,"end_time":"2025-04-20T14:27:21.979609","exception":false,"start_time":"2025-04-20T14:27:21.974463","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# @title 2. Embeddings: Generate Embeddings for Drinks\n\n# --- Embedding Generation Function ---\ndef get_embeddings(texts, model_name=EMBEDDING_MODEL_NAME):\n    \"\"\"\n    Generates embeddings for a list of texts using the specified Gemini model.\n\n    Args:\n        texts (list): A list of strings to embed.\n        model_name (str): The name of the embedding model to use.\n\n    Returns:\n        np.ndarray: A numpy array containing the embeddings, or None if an error occurs.\n    \"\"\"\n    try:\n        # Request embeddings from the Gemini API\n        # 'content' should be the text to embed\n        # 'task_type' helps the model optimize for retrieval\n        result = genai.embed_content(model=model_name,\n                                     content=texts,\n                                     task_type=\"RETRIEVAL_DOCUMENT\") # Use RETRIEVAL_DOCUMENT for the items being stored\n        # Return the embeddings as a numpy array\n        return np.array(result['embedding'])\n    except Exception as e:\n        # Print an error message if embedding fails\n        print(f\"An error occurred during embedding generation: {e}\")\n        # Return None to indicate failure\n        return None\n\n# --- Generate and Store Drink Embeddings ---\n\nprint(\"\\nGenerating embeddings for the nike dataset...\")\n# Get the combined text descriptions for all drinks\ndrink_texts = df_drinks['Combined_Text'].tolist()\n# Generate embeddings for these texts\ndrink_embeddings = get_embeddings(drink_texts)\n\n# Check if embeddings were generated successfully\nif drink_embeddings is not None:\n    # Print the shape of the resulting embedding array (Num Drinks x Embedding Dimension)\n    print(f\"Successfully generated {drink_embeddings.shape[0]} embeddings with dimension {drink_embeddings.shape[1]}.\")\nelse:\n    # Print error message if embeddings failed\n    print(\"Failed to generate embeddings for the nike dataset.\")","metadata":{"execution":{"iopub.status.busy":"2025-05-22T11:23:47.661519Z","iopub.execute_input":"2025-05-22T11:23:47.661939Z","iopub.status.idle":"2025-05-22T11:23:47.718269Z","shell.execute_reply.started":"2025-05-22T11:23:47.661907Z","shell.execute_reply":"2025-05-22T11:23:47.712588Z"},"papermill":{"duration":0.68494,"end_time":"2025-04-20T14:27:22.66984","exception":false,"start_time":"2025-04-20T14:27:21.9849","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"\nGenerating embeddings for the nike dataset...\nAn error occurred during embedding generation: 400 API key not valid. Please pass a valid API key. [reason: \"API_KEY_INVALID\"\ndomain: \"googleapis.com\"\nmetadata {\n  key: \"service\"\n  value: \"generativelanguage.googleapis.com\"\n}\n, locale: \"en-US\"\nmessage: \"API key not valid. Please pass a valid API key.\"\n]\nFailed to generate embeddings for the nike dataset.\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"# Retrieval (RAG Core):\nDefines find_similar_drinks which takes a query_text:\nEmbeds the query using task_type=\"RETRIEVAL_QUERY\".\nCalculates cosine_similarity between the query embedding and all stored drink_embeddings.\nIdentifies the top_n drinks with the highest similarity scores.\nReturns a DataFrame containing these most relevant drinks.\nIncludes a simple test to show how RAG retrieves relevant items.","metadata":{"papermill":{"duration":0.005745,"end_time":"2025-04-20T14:27:22.681457","exception":false,"start_time":"2025-04-20T14:27:22.675712","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# @title 3. Retrieval (RAG Core): Find Similar Drinks\n\n# --- Similarity Search Function ---\ndef find_similar_drinks(query_text, top_n=5):\n    \"\"\"\n    Finds the most similar drinks in the dataset based on semantic similarity\n    of their embeddings to the query embedding.\n\n    Args:\n        query_text (str): The user's query (e.g., \"low sugar fruity drink\").\n        top_n (int): The number of top similar drinks to return.\n\n    Returns:\n        pd.DataFrame: A DataFrame containing the top_n most similar drinks,\n                      or None if embeddings are not available or an error occurs.\n    \"\"\"\n    # Check if drink embeddings are available\n    if drink_embeddings is None:\n        # Print error if embeddings haven't been generated\n        print(\"Error: Drink embeddings are not available.\")\n        # Return None indicating failure\n        return None\n\n    try:\n        # 1. Embed the user query\n        # Use task_type=\"RETRIEVAL_QUERY\" for the user's search query\n        query_embedding_response = genai.embed_content(model=EMBEDDING_MODEL_NAME,\n                                                     content=query_text,\n                                                     task_type=\"RETRIEVAL_QUERY\") # Use RETRIEVAL_QUERY for the search input\n        # Extract the embedding vector\n        query_embedding = np.array(query_embedding_response['embedding']).reshape(1, -1) # Reshape for compatibility with cosine_similarity\n\n        # 2. Calculate Similarity\n        # Compute cosine similarity between the query embedding and all drink embeddings\n        similarities = cosine_similarity(query_embedding, drink_embeddings)[0] # Get the similarity scores\n\n        # 3. Get Top N Indices\n        # Find the indices of the top N highest similarity scores (excluding the query itself if it were in the dataset)\n        # argsort sorts in ascending order, so we take the last 'top_n' elements for highest similarity\n        top_indices = np.argsort(similarities)[-top_n:][::-1] # Reverse to get descending order\n\n        # 4. Retrieve Top N Drinks\n        # Select the rows from the original DataFrame corresponding to the top indices\n        similar_drinks_df = df_drinks.iloc[top_indices].copy() # Use .copy() to avoid SettingWithCopyWarning\n        # Add the similarity score to the DataFrame for context\n        similar_drinks_df['similarity_score'] = similarities[top_indices]\n        # Return the DataFrame of similar drinks\n        return similar_drinks_df\n\n    except Exception as e:\n        # Print error message if similarity search fails\n        print(f\"An error occurred during similarity search: {e}\")\n        # Return None indicating failure\n        return None\n\n# --- Example Usage ---\nprint(\"\\n--- RAG Test: Finding similar drinks ---\")\n# Define a sample query\ntest_query = \"I want something bubbly and fruity but without sugar\"\n# Find similar drinks using the function\nsimilar_results = find_similar_drinks(test_query, top_n=3)\n\n# Check if results were returned\nif similar_results is not None:\n    # Print the names and similarity scores of the found drinks\n    print(f\"Drinks similar to '{test_query}':\")\n    # Iterate through the results and print details\n    for index, row in similar_results.iterrows():\n        # Print name and similarity score, formatted to 3 decimal places\n        print(f\"  - {row['Name']} (Similarity: {row['similarity_score']:.3f})\")\nelse:\n    # Print message if no results found or error occurred\n    print(\"Could not retrieve similar drinks.\")","metadata":{"execution":{"iopub.status.busy":"2025-05-22T11:33:31.667665Z","iopub.execute_input":"2025-05-22T11:33:31.668108Z","iopub.status.idle":"2025-05-22T11:33:31.686516Z","shell.execute_reply.started":"2025-05-22T11:33:31.668077Z","shell.execute_reply":"2025-05-22T11:33:31.679699Z"},"papermill":{"duration":0.338947,"end_time":"2025-04-20T14:27:23.025957","exception":false,"start_time":"2025-04-20T14:27:22.68701","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"\n--- RAG Test: Finding similar drinks ---\nError: Drink embeddings are not available.\nCould not retrieve similar drinks.\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"# Function Calling:\nDefines a Python function find_drinks_by_criteria that filters the df_drinks DataFrame based on arguments like max_calories, max_sugar, etc. This function directly addresses structured dietary queries.\nDefines find_drinks_tool using genai.protos.FunctionDeclaration. This describes the Python function's name, purpose, and parameters to the Gemini model.\nCreates a tools configuration object containing the function declaration.\nSets up available_functions mapping to easily call the Python function when the model requests it.","metadata":{"papermill":{"duration":0.00527,"end_time":"2025-04-20T14:27:23.037333","exception":false,"start_time":"2025-04-20T14:27:23.032063","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# @title 4. Function Calling: Define Tools for Specific Queries\n\n# --- Define Python Functions ---\n# These functions will be callable by the Gemini model.\n\ndef find_drinks_by_criteria(\n    max_calories: int = None,\n    max_sugar: int = None,\n    must_be_caffeine_free: bool = False,\n    must_be_sugar_free: bool = False,\n    must_be_zero_calorie: bool = False\n) -> str:\n    \"\"\"\n    Filters the drink list based on specific nutritional criteria.\n\n    Args:\n        max_calories (int, optional): Maximum calories allowed per 12oz serving. Defaults to None.\n        max_sugar (int, optional): Maximum sugar (in grams) allowed per 12oz serving. Defaults to None.\n        must_be_caffeine_free (bool, optional): If True, only returns caffeine-free drinks. Defaults to False.\n        must_be_sugar_free (bool, optional): If True, only returns sugar-free drinks. Defaults to False.\n        must_be_zero_calorie (bool, optional): If True, only returns zero-calorie drinks. Defaults to False.\n\n    Returns:\n        str: A JSON string representing a list of drinks that meet the criteria,\n             including their name, calories, sugar, and caffeine content.\n             Returns an empty list string '[]' if no drinks match.\n    \"\"\"\n    # Start with the full DataFrame\n    filtered_df = df_drinks.copy()\n\n    # Apply filters based on the arguments provided\n    if max_calories is not None:\n        # Filter by maximum calories\n        filtered_df = filtered_df[filtered_df['Calories (per 12oz)'] <= max_calories]\n    if max_sugar is not None:\n        # Filter by maximum sugar\n        filtered_df = filtered_df[filtered_df['Sugar (g per 12oz)'] <= max_sugar]\n    if must_be_caffeine_free:\n        # Filter for caffeine-free drinks\n        filtered_df = filtered_df[filtered_df['Is_Caffeine_Free'] == True]\n    if must_be_sugar_free:\n        # Filter for sugar-free drinks\n        filtered_df = filtered_df[filtered_df['Is_Sugar_Free'] == True]\n    if must_be_zero_calorie:\n        # Filter for zero-calorie drinks\n        filtered_df = filtered_df[filtered_df['Is_Zero_Calorie'] == True]\n\n    # Select relevant columns for the output\n    results = filtered_df[['Name', 'Calories (per 12oz)', 'Sugar (g per 12oz)', 'Caffeine (mg per 12oz)']].to_dict(orient='records')\n\n    # Return the results as a JSON string\n    return json.dumps(results)\n\n# --- Define Function Declarations for Gemini ---\n# This tells the Gemini model about the available Python functions,\n# their parameters, and what they do.\n\n# Create a FunctionDeclaration object for the find_drinks_by_criteria function\nfind_drinks_tool = genai.protos.FunctionDeclaration(\n    name=\"find_drinks_by_criteria\", # The exact name of the Python function\n    description=\"Finds carbonated drinks based on specific nutritional limits like maximum calories, maximum sugar, or whether they must be caffeine-free, sugar-free, or zero-calorie.\", # Description for the model\n    parameters=genai.protos.Schema( # Define the parameters the function accepts\n        type=genai.protos.Type.OBJECT, # Parameters are defined as an object\n        properties={ # Dictionary of parameter names and their schemas\n            \"max_calories\": genai.protos.Schema(type=genai.protos.Type.INTEGER, description=\"Maximum calories per 12oz serving.\"),\n            \"max_sugar\": genai.protos.Schema(type=genai.protos.Type.INTEGER, description=\"Maximum sugar in grams per 12oz serving.\"),\n            \"must_be_caffeine_free\": genai.protos.Schema(type=genai.protos.Type.BOOLEAN, description=\"Whether the drink must be caffeine-free.\"),\n            \"must_be_sugar_free\": genai.protos.Schema(type=genai.protos.Type.BOOLEAN, description=\"Whether the drink must be sugar-free.\"),\n            \"must_be_zero_calorie\": genai.protos.Schema(type=genai.protos.Type.BOOLEAN, description=\"Whether the drink must be zero-calorie.\")\n        }\n    )\n)\n\n# --- Tool Configuration ---\n# Create a Tool object containing the function declarations\n# This will be passed to the Gemini model during generation.\ntools = genai.protos.Tool(\n    function_declarations=[find_drinks_tool]\n)\n\n# --- Mapping Function Names to Functions ---\n# Create a dictionary to easily call the correct Python function based on the name returned by the model\navailable_functions = {\n    \"find_drinks_by_criteria\": find_drinks_by_criteria,\n}\n\nprint(\"\\nFunction Calling Tools defined:\")\nprint(f\"- {find_drinks_tool.name}: {find_drinks_tool.description}\")","metadata":{"execution":{"iopub.status.busy":"2025-05-22T11:33:37.505526Z","iopub.execute_input":"2025-05-22T11:33:37.505908Z","iopub.status.idle":"2025-05-22T11:33:37.522981Z","shell.execute_reply.started":"2025-05-22T11:33:37.505879Z","shell.execute_reply":"2025-05-22T11:33:37.517946Z"},"papermill":{"duration":0.019701,"end_time":"2025-04-20T14:27:23.062474","exception":false,"start_time":"2025-04-20T14:27:23.042773","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"\nFunction Calling Tools defined:\n- find_drinks_by_criteria: Finds carbonated drinks based on specific nutritional limits like maximum calories, maximum sugar, or whether they must be caffeine-free, sugar-free, or zero-calorie.\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"# Structured Output (JSON Mode): \nDefines json_output_schema, a Python dictionary describing the desired JSON structure for the final recommendations (a list of objects, each with name, reasoning, calories, etc.).\nCreates generation_config_json using genai.types.GenerationConfig, specifying response_mime_type=\"application/json\" and providing the schema.","metadata":{"papermill":{"duration":0.005238,"end_time":"2025-04-20T14:27:23.073402","exception":false,"start_time":"2025-04-20T14:27:23.068164","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# @title 5. Structured Output (JSON Mode): Define Output Schema\n\n# Define the desired JSON structure for the final recommendation output.\n# This helps ensure the model returns data in a predictable and usable format.\n\n# Define the JSON schema using a Python dictionary\n# This specifies the expected structure of the model's final output.\njson_output_schema = {\n  \"type\": \"object\", # The top-level structure is an object\n  \"properties\": { # Define the fields within the object\n    \"recommendations\": { # A field named \"recommendations\"\n      \"type\": \"array\", # This field should contain an array\n      \"description\": \"A list of recommended carbonated drinks based on the user query and retrieved context.\", # Description of the field\n      \"items\": { # Define the structure of each item within the array\n        \"type\": \"object\", # Each item is an object\n        \"properties\": { # Define the fields within each recommendation object\n          \"name\": {\n            \"type\": \"string\", # Drink name should be a string\n            \"description\": \"The name of the recommended drink.\" # Description\n          },\n          \"reasoning\": {\n            \"type\": \"string\", # Reasoning should be a string\n            \"description\": \"Explanation why this drink is recommended based on the user query and drink properties.\" # Description\n          },\n          \"calories\": {\n            \"type\": \"number\", # Calories should be a number\n            \"description\": \"Calories per 12oz serving.\" # Description\n          },\n          \"sugar_g\": {\n            \"type\": \"number\", # Sugar should be a number\n            \"description\": \"Grams of sugar per 12oz serving.\" # Description\n          },\n          \"caffeine_mg\": {\n            \"type\": \"number\", # Caffeine should be a number\n            \"description\": \"Milligrams of caffeine per 12oz serving.\" # Description\n          }\n        },\n        \"required\": [\"name\", \"reasoning\", \"calories\", \"sugar_g\", \"caffeine_mg\"] # These fields must be present in each recommendation\n      }\n    }\n  },\n  \"required\": [\"recommendations\"] # The \"recommendations\" field is mandatory in the overall output\n}\n\n\n# --- Generation Configuration ---\n# Configure the generative model to use JSON mode with the defined schema.\ngeneration_config_json = genai.types.GenerationConfig(\n    response_mime_type=\"application/json\", # Specify the desired output format\n    response_schema=json_output_schema # Provide the schema definition\n)\n\nprint(\"\\nJSON Output Schema defined for structured recommendations.\")","metadata":{"execution":{"iopub.status.busy":"2025-05-22T11:33:49.007701Z","iopub.execute_input":"2025-05-22T11:33:49.008098Z","iopub.status.idle":"2025-05-22T11:33:49.02012Z","shell.execute_reply.started":"2025-05-22T11:33:49.008069Z","shell.execute_reply":"2025-05-22T11:33:49.017223Z"},"papermill":{"duration":0.015247,"end_time":"2025-04-20T14:27:23.094006","exception":false,"start_time":"2025-04-20T14:27:23.078759","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"\nJSON Output Schema defined for structured recommendations.\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"# The Recommender Function (get_drink_recommendations):\nInitializes the generative model (gemini-1.5-flash-latest).\n\nTakes the user_query.\n\n**RAG Step**: Calls find_similar_drinks to get relevant context.\n\n**Prompt Construction**: Creates a detailed prompt for the Gemini model, including its role, the user_query, the rag_context, and instructions on how to generate recommendations, consider functions, and format the output.\n\n**Model Interaction**:\nUses model.start_chat(enable_automatic_function_calling=True) which simplifies handling function calls. \nThe SDK automatically handles the loop: \n    Model requests call -> SDK executes function -> SDK sends result back -> Model generates final response.\nSends the initial prompt.\n\n**Final Response Processing**:\nAfter potential function calls, the final response might still be text. To enforce the JSON structure strictly, it takes the final text response, creates a new prompt asking the model to format that text according to the JSON schema.\nCalls model.generate_content with this new prompt and the generation_config_json.\nParses the resulting JSON text using json.loads().\n\n**Run the Recommender**: Provides several example user_query strings demonstrating different types of requests (general preference, specific constraints likely to trigger function calls, flavor focus) and prints the resulting structured JSON recommendations.","metadata":{"papermill":{"duration":0.005564,"end_time":"2025-04-20T14:27:23.105409","exception":false,"start_time":"2025-04-20T14:27:23.099845","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# @title 6. The Recommender Function\n\n# --- Initialize the Generative Model ---\n# Create an instance of the Gemini Pro model configured for function calling and JSON output.\n# We use the specific config for JSON output only when we expect the *final* answer in JSON.\n# Function call responses are handled separately.\nmodel = genai.GenerativeModel(\n    GENERATIVE_MODEL_NAME,\n    # tools=[tools] # Tools are added dynamically during the conversation\n)\n\n# --- Main Recommender Function ---\ndef get_drink_recommendations(user_query, rag_top_n=5):\n    \"\"\"\n    Generates personalized drink recommendations based on user query,\n    using RAG, Function Calling, and Structured Output.\n\n    Args:\n        user_query (str): The user's request for a drink recommendation.\n        rag_top_n (int): The number of relevant documents to retrieve for RAG context.\n\n    Returns:\n        dict: A dictionary containing the structured recommendations (if successful),\n              or an error message.\n    \"\"\"\n    print(f\"\\n--- Processing Query: '{user_query}' ---\")\n\n    # 1. RAG - Retrieve Relevant Drinks\n    print(f\"Step 1: Retrieving top {rag_top_n} relevant drinks (RAG)...\")\n    # Find drinks semantically similar to the user query\n    similar_drinks = find_similar_drinks(user_query, top_n=rag_top_n)\n\n    # Check if retrieval was successful\n    if similar_drinks is None or similar_drinks.empty:\n        # Handle case where no similar drinks are found\n        print(\"RAG: Could not find relevant drinks based on the query.\")\n        # Provide context as an empty list string\n        rag_context = \"[]\"\n    else:\n        # Format the retrieved drink data as context for the LLM\n        # Convert selected columns of the similar drinks DataFrame to a list of dictionaries\n        context_list = similar_drinks[['Name', 'Description', 'Flavor Profile', 'Calories (per 12oz)', 'Sugar (g per 12oz)', 'Caffeine (mg per 12oz)', 'Is_Sugar_Free', 'Is_Caffeine_Free', 'Is_Zero_Calorie', 'Ingredients']].to_dict(orient='records')\n        # Convert the list of dictionaries to a JSON string\n        rag_context = json.dumps(context_list, indent=2) # Pretty print JSON for readability\n        \n        \n    # 2. Prepare the Prompt for the LLM\n    # Construct a detailed prompt incorporating the user query and the RAG context.\n    # Instruct the model on its role, the context, dietary considerations, function use, and desired output format.\n    prompt = f\"\"\"\n    You are a helpful Carbonated Drink Recommender assistant.\n    Your goal is to provide personalized drink recommendations based on the user's preferences and dietary needs.\n    You should prioritize health considerations mentioned (low sugar, low calorie, caffeine-free etc.).\n\n    USER QUERY: \"{user_query}\"\n\n    CONTEXT FROM DRINK DATABASE (use this information to ground your recommendations):\n    ```json\n    {rag_context}\n    ```\n\n    INSTRUCTIONS:\n    1. Analyze the USER QUERY to understand their preferences (flavor, type, dietary restrictions like low sugar, caffeine-free, specific calorie limits).\n    2. Use the provided CONTEXT to find drinks that match the user's query.\n    3. If the query involves specific, filterable criteria (e.g., \"drinks under 50 calories\", \"list all sugar-free options\"), consider using the 'find_drinks_by_criteria' function if appropriate. The function returns a list of drinks matching exact numerical or boolean criteria. You can use the function's output to supplement or replace the RAG context if it's more direct for the query.\n    4. Generate a list of 1-3 recommended drinks.\n    5. For each recommendation, provide:\n        - The drink's name.\n        - A brief reasoning explaining *why* it fits the user's query, referencing the context or function call results.\n        - Key nutritional info: calories, sugar (g), caffeine (mg).\n    6. Format your FINAL output STRICTLY as a JSON object matching the provided schema. Do not include any text before or after the JSON object.\n    \"\"\"\n\n    # 3. Interact with the Gemini Model (potentially with function calls)\n    print(\"Step 2: Generating recommendations with Gemini...\")\n\n    try:\n        # Start a chat session to handle potential function call loops\n        chat = model.start_chat(enable_automatic_function_calling=True) # Let the SDK handle the function call loop\n\n        # Send the initial prompt with tools configured for this turn\n        # Note: We send the prompt and *also* pass the tools configuration.\n        # The generation_config for JSON is applied *after* any function calls complete.\n        response = chat.send_message(\n            prompt\n        )\n\n        # Automatic Function Calling handles the back-and-forth if the model decides to call a function.\n        # The 'response' object will contain the *final* response after any function calls are resolved.\n\n        # Check for errors in the final response (e.g., safety blocks)\n        if not response.parts:\n             # Handle cases where the response might be blocked or empty\n            print(\"Error: Received an empty or blocked response from the model.\")\n            # Check candidate for specific block reason if available\n            if response.candidates and response.candidates[0].finish_reason.name != \"STOP\":\n                print(f\"Reason: {response.candidates[0].finish_reason.name}\")\n                # You might also check response.prompt_feedback for block reasons\n                if hasattr(response, 'prompt_feedback') and response.prompt_feedback.block_reason:\n                   print(f\"Block Reason: {response.prompt_feedback.block_reason}\")\n\n            return {\"error\": \"Model response was empty or blocked.\"}\n\n\n        # 4. Process Final Response (Expecting JSON)\n        print(\"Step 3: Processing final response...\")\n        # At this stage, we expect the final answer, potentially after function calls.\n        # Now, configure the model *specifically* for JSON output using the final text content.\n        # This is a slightly different approach than forcing JSON from the start if function calls might occur.\n        # Alternative: If you *know* the final response *must* be JSON, you could re-send the final prompt content\n        # (potentially including function results) with the JSON generation config.\n\n        # Let's try to parse the text content assuming it should be JSON.\n        # The automatic function calling might return the final result as text,\n        # even if the function call itself returned JSON. We need to guide the *final* generation.\n\n        # --- Re-generating the final response with JSON mode ---\n        # We take the content generated *after* potential function calls and ask the model\n        # to format *that content* into the desired JSON structure.\n\n        # Get the text content from the response potentially generated after function calls\n        final_content_for_json = response.text\n\n        # Create a new prompt specifically asking for JSON formatting of the previous response.\n        json_formatting_prompt = f\"\"\"\n        Please format the following drink recommendation information into the specified JSON schema.\n        Do not add any extra commentary. Output only the JSON object.\n\n        Information to format:\n        {final_content_for_json}\n\n        JSON Schema to conform to:\n        ```json\n        {json.dumps(json_output_schema, indent=2)}\n        ```\n        \"\"\"\n\n        # Generate the final response using JSON mode\n        json_response = model.generate_content(\n            json_formatting_prompt,\n            generation_config=generation_config_json,\n            # No tools needed for this final formatting step\n        )\n\n\n        # Check if the JSON response has content\n        if not json_response.parts:\n             # Handle cases where the response might be blocked or empty\n            print(\"Error: Received an empty or blocked response during JSON formatting.\")\n            # Check candidate for specific block reason if available\n            if json_response.candidates and json_response.candidates[0].finish_reason.name != \"STOP\":\n                print(f\"Reason: {json_response.candidates[0].finish_reason.name}\")\n                 # You might also check response.prompt_feedback for block reasons\n                if hasattr(json_response, 'prompt_feedback') and json_response.prompt_feedback.block_reason:\n                   print(f\"Block Reason: {json_response.prompt_feedback.block_reason}\")\n            return {\"error\": \"Model response was empty or blocked during JSON formatting.\"}\n\n\n        # Extract and parse the JSON output\n        try:\n            # Access the text part of the response\n            json_output_text = json_response.text\n            # Parse the text as JSON\n            structured_output = json.loads(json_output_text)\n            # Print success message\n            print(\"Successfully parsed structured JSON output.\")\n            # Return the parsed dictionary\n            return structured_output\n        except json.JSONDecodeError as e:\n            # Handle JSON parsing errors\n            print(f\"Error: Failed to decode JSON response: {e}\")\n            # Print the raw response text for debugging\n            print(\"Raw model response text for JSON formatting:\")\n            print(json_response.text)\n            # Return an error dictionary\n            return {\"error\": \"Failed to parse JSON output from the model.\", \"raw_response\": json_response.text}\n        except Exception as e:\n             # Handle other potential errors during JSON processing\n            print(f\"An unexpected error occurred processing the JSON response: {e}\")\n            print(\"Raw model response text for JSON formatting:\")\n            print(json_response.text)\n            return {\"error\": f\"An unexpected error occurred: {e}\", \"raw_response\": json_response.text}\n\n\n    except Exception as e:\n        # Handle any errors during the Gemini API call or processing\n        print(f\"An error occurred during recommendation generation: {e}\")\n        # Return an error dictionary\n        return {\"error\": str(e)}","metadata":{"execution":{"iopub.status.busy":"2025-05-22T11:33:59.21517Z","iopub.execute_input":"2025-05-22T11:33:59.215547Z","iopub.status.idle":"2025-05-22T11:33:59.23756Z","shell.execute_reply.started":"2025-05-22T11:33:59.215517Z","shell.execute_reply":"2025-05-22T11:33:59.232751Z"},"papermill":{"duration":0.023455,"end_time":"2025-04-20T14:27:23.134505","exception":false,"start_time":"2025-04-20T14:27:23.11105","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"","metadata":{"papermill":{"duration":0.005879,"end_time":"2025-04-20T14:27:23.147148","exception":false,"start_time":"2025-04-20T14:27:23.141269","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# **Run the Recommender**\n\nExample queries","metadata":{"papermill":{"duration":0.005861,"end_time":"2025-04-20T14:27:23.158718","exception":false,"start_time":"2025-04-20T14:27:23.152857","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# @title 7. Run the Recommender: Example Queries\n\n# --- Example 1: Preference for low sugar ---\nquery1 = \"I'm looking for a refreshing drink, maybe something fruity, but low in sugar.\"\nrecommendations1 = get_drink_recommendations(query1)\nprint(\"\\n--- Recommendations for Query 1 ---\")\n# Pretty print the JSON output\nprint(json.dumps(recommendations1, indent=2))\n\n# --- Example 2: Specific dietary constraint (triggering function call) ---\nquery2 = \"Show me drinks that have less than 10 grams of sugar and are caffeine free.\"\n# This query is likely to trigger the 'find_drinks_by_criteria' function.\nrecommendations2 = get_drink_recommendations(query2)\nprint(\"\\n--- Recommendations for Query 2 (Function Call Likely) ---\")\n# Pretty print the JSON output\nprint(json.dumps(recommendations2, indent=2))\n\n# --- Example 3: Flavor preference ---\nquery3 = \"I want a classic cola taste.\"\nrecommendations3 = get_drink_recommendations(query3)\nprint(\"\\n--- Recommendations for Query 3 ---\")\n# Pretty print the JSON output\nprint(json.dumps(recommendations3, indent=2))\n\n# --- Example 4: Zero Calorie preference ---\nquery4 = \"Are there any zero calorie options available?\"\nrecommendations4 = get_drink_recommendations(query4)\nprint(\"\\n--- Recommendations for Query 4 ---\")\n# Pretty print the JSON output\nprint(json.dumps(recommendations4, indent=2))\n\n# --- Example 5: Energy boost needed ---\nquery5 = \"I need an energy drink, preferably without sugar.\"\nrecommendations5 = get_drink_recommendations(query5)\nprint(\"\\n--- Recommendations for Query 5 ---\")\n# Pretty print the JSON output\nprint(json.dumps(recommendations5, indent=2))","metadata":{"execution":{"iopub.status.busy":"2025-05-22T11:34:07.738488Z","iopub.execute_input":"2025-05-22T11:34:07.738908Z","iopub.status.idle":"2025-05-22T11:34:08.292895Z","shell.execute_reply.started":"2025-05-22T11:34:07.738874Z","shell.execute_reply":"2025-05-22T11:34:08.28762Z"},"papermill":{"duration":17.169079,"end_time":"2025-04-20T14:27:40.333579","exception":false,"start_time":"2025-04-20T14:27:23.1645","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"\n--- Processing Query: 'I'm looking for a refreshing drink, maybe something fruity, but low in sugar.' ---\nStep 1: Retrieving top 5 relevant drinks (RAG)...\nError: Drink embeddings are not available.\nRAG: Could not find relevant drinks based on the query.\nStep 2: Generating recommendations with Gemini...\nAn error occurred during recommendation generation: 400 API key not valid. Please pass a valid API key. [reason: \"API_KEY_INVALID\"\ndomain: \"googleapis.com\"\nmetadata {\n  key: \"service\"\n  value: \"generativelanguage.googleapis.com\"\n}\n, locale: \"en-US\"\nmessage: \"API key not valid. Please pass a valid API key.\"\n]\n\n--- Recommendations for Query 1 ---\n{\n  \"error\": \"400 API key not valid. Please pass a valid API key. [reason: \\\"API_KEY_INVALID\\\"\\ndomain: \\\"googleapis.com\\\"\\nmetadata {\\n  key: \\\"service\\\"\\n  value: \\\"generativelanguage.googleapis.com\\\"\\n}\\n, locale: \\\"en-US\\\"\\nmessage: \\\"API key not valid. Please pass a valid API key.\\\"\\n]\"\n}\n\n--- Processing Query: 'Show me drinks that have less than 10 grams of sugar and are caffeine free.' ---\nStep 1: Retrieving top 5 relevant drinks (RAG)...\nError: Drink embeddings are not available.\nRAG: Could not find relevant drinks based on the query.\nStep 2: Generating recommendations with Gemini...\nAn error occurred during recommendation generation: 400 API key not valid. Please pass a valid API key. [reason: \"API_KEY_INVALID\"\ndomain: \"googleapis.com\"\nmetadata {\n  key: \"service\"\n  value: \"generativelanguage.googleapis.com\"\n}\n, locale: \"en-US\"\nmessage: \"API key not valid. Please pass a valid API key.\"\n]\n\n--- Recommendations for Query 2 (Function Call Likely) ---\n{\n  \"error\": \"400 API key not valid. Please pass a valid API key. [reason: \\\"API_KEY_INVALID\\\"\\ndomain: \\\"googleapis.com\\\"\\nmetadata {\\n  key: \\\"service\\\"\\n  value: \\\"generativelanguage.googleapis.com\\\"\\n}\\n, locale: \\\"en-US\\\"\\nmessage: \\\"API key not valid. Please pass a valid API key.\\\"\\n]\"\n}\n\n--- Processing Query: 'I want a classic cola taste.' ---\nStep 1: Retrieving top 5 relevant drinks (RAG)...\nError: Drink embeddings are not available.\nRAG: Could not find relevant drinks based on the query.\nStep 2: Generating recommendations with Gemini...\nAn error occurred during recommendation generation: 400 API key not valid. Please pass a valid API key. [reason: \"API_KEY_INVALID\"\ndomain: \"googleapis.com\"\nmetadata {\n  key: \"service\"\n  value: \"generativelanguage.googleapis.com\"\n}\n, locale: \"en-US\"\nmessage: \"API key not valid. Please pass a valid API key.\"\n]\n\n--- Recommendations for Query 3 ---\n{\n  \"error\": \"400 API key not valid. Please pass a valid API key. [reason: \\\"API_KEY_INVALID\\\"\\ndomain: \\\"googleapis.com\\\"\\nmetadata {\\n  key: \\\"service\\\"\\n  value: \\\"generativelanguage.googleapis.com\\\"\\n}\\n, locale: \\\"en-US\\\"\\nmessage: \\\"API key not valid. Please pass a valid API key.\\\"\\n]\"\n}\n\n--- Processing Query: 'Are there any zero calorie options available?' ---\nStep 1: Retrieving top 5 relevant drinks (RAG)...\nError: Drink embeddings are not available.\nRAG: Could not find relevant drinks based on the query.\nStep 2: Generating recommendations with Gemini...\nAn error occurred during recommendation generation: 400 API key not valid. Please pass a valid API key. [reason: \"API_KEY_INVALID\"\ndomain: \"googleapis.com\"\nmetadata {\n  key: \"service\"\n  value: \"generativelanguage.googleapis.com\"\n}\n, locale: \"en-US\"\nmessage: \"API key not valid. Please pass a valid API key.\"\n]\n\n--- Recommendations for Query 4 ---\n{\n  \"error\": \"400 API key not valid. Please pass a valid API key. [reason: \\\"API_KEY_INVALID\\\"\\ndomain: \\\"googleapis.com\\\"\\nmetadata {\\n  key: \\\"service\\\"\\n  value: \\\"generativelanguage.googleapis.com\\\"\\n}\\n, locale: \\\"en-US\\\"\\nmessage: \\\"API key not valid. Please pass a valid API key.\\\"\\n]\"\n}\n\n--- Processing Query: 'I need an energy drink, preferably without sugar.' ---\nStep 1: Retrieving top 5 relevant drinks (RAG)...\nError: Drink embeddings are not available.\nRAG: Could not find relevant drinks based on the query.\nStep 2: Generating recommendations with Gemini...\nAn error occurred during recommendation generation: 400 API key not valid. Please pass a valid API key. [reason: \"API_KEY_INVALID\"\ndomain: \"googleapis.com\"\nmetadata {\n  key: \"service\"\n  value: \"generativelanguage.googleapis.com\"\n}\n, locale: \"en-US\"\nmessage: \"API key not valid. Please pass a valid API key.\"\n]\n\n--- Recommendations for Query 5 ---\n{\n  \"error\": \"400 API key not valid. Please pass a valid API key. [reason: \\\"API_KEY_INVALID\\\"\\ndomain: \\\"googleapis.com\\\"\\nmetadata {\\n  key: \\\"service\\\"\\n  value: \\\"generativelanguage.googleapis.com\\\"\\n}\\n, locale: \\\"en-US\\\"\\nmessage: \\\"API key not valid. Please pass a valid API key.\\\"\\n]\"\n}\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"# **Documentation and Explanation** : \n\nA detailed markdown cell explaining all the concepts (Embeddings, RAG, Function Calling, JSON Mode, Long Context, Dietary Needs) and how they are implemented in the notebook.","metadata":{"papermill":{"duration":0.006284,"end_time":"2025-04-20T14:27:40.347145","exception":false,"start_time":"2025-04-20T14:27:40.340861","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# @title 8. Conclusion\n\nprint(\"\\n\" + \"=\"*50)\nprint(\" Personalized Carbonated Drink Recommender Demo Finished \")\nprint(\"=\"*50)\nprint(\"This notebook demonstrated building a recommender using Gemini:\")\nprint(\"- Embeddings for semantic search\")\nprint(\"- RAG for grounding recommendations in data\")\nprint(\"- Function Calling for specific data filtering\")\nprint(\"- Structured JSON output for predictable results\")\nprint(\"- Implicit use of Long Context via RAG\")\nprint(\"- Incorporation of dietary/health needs\")","metadata":{"execution":{"iopub.execute_input":"2025-04-20T14:27:40.361769Z","iopub.status.busy":"2025-04-20T14:27:40.36131Z","iopub.status.idle":"2025-04-20T14:27:40.367459Z","shell.execute_reply":"2025-04-20T14:27:40.366274Z"},"papermill":{"duration":0.015323,"end_time":"2025-04-20T14:27:40.369024","exception":false,"start_time":"2025-04-20T14:27:40.353701","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Conclusion**: \n\nA brief summary message.\nThis notebook provides a comprehensive, runnable example demonstrating the powerful features of Gemini for building sophisticated, context-aware, and controllable AI applications.\n\nGithub - https://github.com/ramansv710/genai-5-day-course/blob/dev/personalized-carbonated-drink-recommender.ipynb\n\nBlog - https://ramansv710.blogspot.com/2025/04/ai-powered-fizz-building-personalized.html","metadata":{"papermill":{"duration":0.006208,"end_time":"2025-04-20T14:27:40.382125","exception":false,"start_time":"2025-04-20T14:27:40.375917","status":"completed"},"tags":[]}}]}